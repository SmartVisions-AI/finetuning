# Experiment: SFT-Feinabstimmung

## Beschreibung

Llama 8B Distill-Version von deepseek

Modelle können auch hier gefunden werden: [Hugginface Collection](https://huggingface.co/collections/moslehGen/sft-681ccba9ae754cd58d2e9b2c)

## Inhalt

| Notizbuch | Beschreibung | Modell Repo |
|----------|-------------|-------------|
| `Tourism_fine_tuning_deepseek_r1.ipynb` | 50K Dataset subset of the 166K recieved | moslehGen/DeepSeek-R1-Distill-Llama-8B-RunPOD-Rows-trained-50000
| Tourismus_Feinabstimmung_Tiefseek_r1 COT.ipynb" | 26K Datensatz, ursprünglich mit Chain-of-Though erhalten | moslehGen/SFT-COT-25K
| Tourismus_Feinabstimmung_Tiefensuche_r1 100K.ipynb" | 100 K Datensatz mit Balanced Sentiments | moslehGen/DeepSeek-R1-Distill-Llama-8B-RunPOD-Rows-trained-100000

## Wie man ausführt

Inferenz mit Colab kann hier gefunden werden: [Colab](https://colab.research.google.com/drive/1y7ecU3swRg98_qW-EIL_AAq816Qrk5qD?usp=sharing)





